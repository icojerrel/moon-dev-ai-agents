"""
ðŸŒ™ Moon Dev's Model Factory
Built with love by Moon Dev ðŸš€

This module manages all available AI models and provides a unified interface.
"""

import os
from typing import Dict, Optional, Type
from termcolor import cprint
from dotenv import load_dotenv
from pathlib import Path
from .base_model import BaseModel
from .claude_model import ClaudeModel
from .groq_model import GroqModel
from .openai_model import OpenAIModel
# from .gemini_model import GeminiModel  # Temporarily disabled due to protobuf conflict
from .deepseek_model import DeepSeekModel
from .ollama_model import OllamaModel
from .xai_model import XAIModel
from .openrouter_model import OpenRouterModel

class ModelFactory:
    """Factory for creating and managing AI models"""
    
    # Map model types to their implementations
    MODEL_IMPLEMENTATIONS = {
        "claude": ClaudeModel,
        "groq": GroqModel,
        "openai": OpenAIModel,
        # "gemini": GeminiModel,  # Temporarily disabled due to protobuf conflict
        "deepseek": DeepSeekModel,
        "ollama": OllamaModel,  # Add Ollama implementation
        "xai": XAIModel,  # xAI Grok models
        "openrouter": OpenRouterModel  # OpenRouter unified API
    }
    
    # Default models for each type
    DEFAULT_MODELS = {
        "claude": "claude-3-5-haiku-latest",  # Latest fast Claude model
        "groq": "mixtral-8x7b-32768",        # Fast Mixtral model
        "openai": "gpt-4o",                  # Latest GPT-4 Optimized
        # "gemini": "gemini-2.0-flash",        # Latest Gemini model (temporarily disabled)
        "deepseek": "deepseek-reasoner",     # Enhanced reasoning model
        "ollama": "llama3.2",                # Meta's Llama 3.2 - balanced performance
        "xai": "grok-4-fast-reasoning",      # xAI's Grok 4 Fast with reasoning (best value: 2M context, cheap!)
        "openrouter": "anthropic/claude-3.5-sonnet"  # OpenRouter default (Claude Sonnet via OpenRouter)
    }
    
    def __init__(self):
        cprint("\nðŸ—ï¸ Creating new ModelFactory instance...", "cyan")
        
        # Load environment variables first
        project_root = Path(__file__).parent.parent.parent
        env_path = project_root / '.env'
        cprint(f"\nðŸ” Loading environment from: {env_path}", "cyan")
        load_dotenv(dotenv_path=env_path)
        cprint("âœ¨ Environment loaded", "green")
        
        self._models: Dict[str, BaseModel] = {}
        self._initialize_models()
    
    def _initialize_models(self):
        """Initialize all available models"""
        initialized = False
        
        cprint("\nðŸ­ Moon Dev's Model Factory Initialization", "cyan")
        cprint("â•" * 50, "cyan")
        
        # Debug current environment without exposing values
        cprint("\nðŸ” Environment Check:", "cyan")
        for key in ["OPENROUTER_API_KEY", "GROQ_API_KEY", "OPENAI_KEY", "ANTHROPIC_KEY", "DEEPSEEK_KEY", "GROK_API_KEY"]:  # GEMINI_KEY temporarily removed
            value = os.getenv(key)
            if value and len(value.strip()) > 0:
                cprint(f"  â”œâ”€ {key}: Found ({len(value)} chars)", "green")
            else:
                cprint(f"  â”œâ”€ {key}: Not found or empty", "red")
        
        # Try to initialize each model type
        for model_type, key_name in self._get_api_key_mapping().items():
            cprint(f"\nðŸ”„ Initializing {model_type} model...", "cyan")
            cprint(f"  â”œâ”€ Looking for {key_name}...", "cyan")
            
            if api_key := os.getenv(key_name):
                try:
                    cprint(f"  â”œâ”€ Found {key_name} ({len(api_key)} chars)", "green")
                    cprint(f"  â”œâ”€ Getting model class for {model_type}...", "cyan")
                    
                    if model_type not in self.MODEL_IMPLEMENTATIONS:
                        cprint(f"  â”œâ”€ âŒ Model type not found in implementations!", "red")
                        cprint(f"  â””â”€ Available implementations: {list(self.MODEL_IMPLEMENTATIONS.keys())}", "yellow")
                        continue
                    
                    model_class = self.MODEL_IMPLEMENTATIONS[model_type]
                    cprint(f"  â”œâ”€ Using model class: {model_class.__name__}", "cyan")
                    
                    # Create instance with more detailed error handling
                    try:
                        cprint(f"  â”œâ”€ Creating model instance...", "cyan")
                        cprint(f"  â”œâ”€ Default model name: {self.DEFAULT_MODELS[model_type]}", "cyan")
                        model_instance = model_class(api_key)
                        cprint(f"  â”œâ”€ Model instance created", "green")
                        
                        # Test if instance is properly initialized
                        cprint(f"  â”œâ”€ Testing model availability...", "cyan")
                        if model_instance.is_available():
                            self._models[model_type] = model_instance
                            initialized = True
                            cprint(f"  â””â”€ âœ¨ Successfully initialized {model_type}", "green")
                        else:
                            cprint(f"  â””â”€ âš ï¸ Model instance created but not available", "yellow")
                    except Exception as instance_error:
                        cprint(f"  â”œâ”€ âš ï¸ Error creating model instance", "yellow")
                        cprint(f"  â”œâ”€ Error type: {type(instance_error).__name__}", "yellow")
                        cprint(f"  â”œâ”€ Error message: {str(instance_error)}", "yellow")
                        if hasattr(instance_error, '__traceback__'):
                            import traceback
                            cprint(f"  â””â”€ Traceback:\n{traceback.format_exc()}", "yellow")
                        
                except Exception as e:
                    cprint(f"  â”œâ”€ âš ï¸ Failed to initialize {model_type} model", "yellow")
                    cprint(f"  â”œâ”€ Error type: {type(e).__name__}", "yellow")
                    cprint(f"  â”œâ”€ Error message: {str(e)}", "yellow")
                    if hasattr(e, '__traceback__'):
                        import traceback
                        cprint(f"  â””â”€ Traceback:\n{traceback.format_exc()}", "yellow")
            else:
                cprint(f"  â””â”€ â„¹ï¸ {key_name} not found", "blue")
        
        # Initialize Ollama separately since it doesn't need an API key
        try:
            cprint("\nðŸ”„ Initializing Ollama model...", "cyan")
            model_class = self.MODEL_IMPLEMENTATIONS["ollama"]
            model_instance = model_class(model_name=self.DEFAULT_MODELS["ollama"])
            
            if model_instance.is_available():
                self._models["ollama"] = model_instance
                initialized = True
                cprint("âœ¨ Successfully initialized Ollama", "green")
            else:
                cprint("âš ï¸ Ollama server not available - make sure 'ollama serve' is running", "yellow")
        except Exception as e:
            cprint(f"âŒ Failed to initialize Ollama: {str(e)}", "red")
        
        cprint("\n" + "â•" * 50, "cyan")
        cprint(f"ðŸ“Š Initialization Summary:", "cyan")
        cprint(f"  â”œâ”€ Models attempted: {len(self._get_api_key_mapping()) + 1}", "cyan")  # +1 for Ollama
        cprint(f"  â”œâ”€ Models initialized: {len(self._models)}", "cyan")
        cprint(f"  â””â”€ Available models: {list(self._models.keys())}", "cyan")
        
        if not initialized:
            cprint("\nâš ï¸ No AI models available - check API keys and Ollama server", "yellow")
            cprint("Required environment variables:", "yellow")
            for model_type, key_name in self._get_api_key_mapping().items():
                cprint(f"  â”œâ”€ {key_name} (for {model_type})", "yellow")
            cprint("  â””â”€ Add these to your .env file ðŸŒ™", "yellow")
            cprint("\nFor Ollama:", "yellow")
            cprint("  â””â”€ Make sure 'ollama serve' is running", "yellow")
        else:
            # Print available models
            cprint("\nðŸ¤– Available AI Models:", "cyan")
            for model_type, model in self._models.items():
                cprint(f"  â”œâ”€ {model_type}: {model.model_name}", "green")
            cprint("  â””â”€ Moon Dev's Model Factory Ready! ðŸŒ™", "green")
    
    def get_model(self, model_type: str, model_name: Optional[str] = None) -> Optional[BaseModel]:
        """Get a specific model instance"""
        cprint(f"\nðŸ” Requesting model: {model_type} ({model_name or 'default'})", "cyan")
        
        if model_type not in self.MODEL_IMPLEMENTATIONS:
            cprint(f"âŒ Invalid model type: '{model_type}'", "red")
            cprint("Available types:", "yellow")
            for available_type in self.MODEL_IMPLEMENTATIONS.keys():
                cprint(f"  â”œâ”€ {available_type}", "yellow")
            return None
            
        if model_type not in self._models:
            key_name = self._get_api_key_mapping().get(model_type)
            if key_name:
                cprint(f"âŒ Model type '{model_type}' not available - check {key_name} in .env", "red")
            else:
                cprint(f"âŒ Model type '{model_type}' not available", "red")
            return None
            
        model = self._models[model_type]
        if model_name and model.model_name != model_name:
            cprint(f"ðŸ”„ Reinitializing {model_type} with model {model_name}...", "cyan")
            try:
                # Special handling for Ollama models
                if model_type == "ollama":
                    model = self.MODEL_IMPLEMENTATIONS[model_type](model_name=model_name)
                else:
                    # For API-based models that need a key
                    if api_key := os.getenv(self._get_api_key_mapping()[model_type]):
                        model = self.MODEL_IMPLEMENTATIONS[model_type](api_key, model_name=model_name)
                    else:
                        cprint(f"âŒ API key not found for {model_type}", "red")
                        return None
                
                self._models[model_type] = model
                cprint(f"âœ¨ Successfully reinitialized with new model", "green")
            except Exception as e:
                cprint(f"âŒ Failed to initialize {model_type} with model {model_name}", "red")
                cprint(f"âŒ Error type: {type(e).__name__}", "red")
                cprint(f"âŒ Error: {str(e)}", "red")
                return None
            
        return model
    
    def _get_api_key_mapping(self) -> Dict[str, str]:
        """Get mapping of model types to their API key environment variable names"""
        return {
            "claude": "ANTHROPIC_KEY",
            "groq": "GROQ_API_KEY",
            "openai": "OPENAI_KEY",
            # "gemini": "GEMINI_KEY",  # Temporarily disabled due to protobuf conflict
            "deepseek": "DEEPSEEK_KEY",
            "xai": "GROK_API_KEY",  # Grok/xAI uses GROK_API_KEY
            "openrouter": "OPENROUTER_API_KEY",  # OpenRouter unified API
            # Ollama doesn't need an API key as it runs locally
        }
    
    @property
    def available_models(self) -> Dict[str, list]:
        """Get all available models and their configurations"""
        return {
            model_type: model.AVAILABLE_MODELS
            for model_type, model in self._models.items()
        }
    
    def is_model_available(self, model_type: str) -> bool:
        """Check if a specific model type is available"""
        return model_type in self._models and self._models[model_type].is_available()

# Create a singleton instance
model_factory = ModelFactory() 